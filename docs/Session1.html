<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fa" xml:lang="fa" dir="rtl"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>session1 – درس هوش مصنوعی</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-fa4b1673990fa3f7be976ac11d59a17c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="quarto-light">

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><h1 style="text-align: center;" class="title display-7">
جلسه ۱: مبانی، معماری و چشم‌انداز هوش مصنوعی: تحلیل جامع
</h1></header>




<div style="text-align: center; margin-top: 2rem;">

<h2 class="anchored">
تحلیل عمیق مفاهیم هسته‌ای، ریشه‌های تاریخی و چارچوب‌های محاسباتی AI
</h2>
<p style="color: var(--color-text-muted); font-size: 1.1rem;">
بررسی جامع تعاریف، پارادایم‌های اصلی، و مسیر تکامل از سایبرنتیک و منطق نمادین تا انقلاب ترانسفورمر
</p>
<hr style="width: 60%; margin: 2rem auto;">
</div>
<section class="section-card">
<h3 class="anchored">
بخش اول: تعاریف، سلسله مراتب و مبانی ریاضی
</h3>
<h4 class="anchored">
۱.۱. تعریف ساختاریافته و تمایز عمیق AI، ML و DL
</h4>
<p>درک این سه مفهوم، یک پیوستار فنی و فلسفی را شکل می‌دهد. <strong>AI یک هدف فلسفی، ML یک متدولوژی آماری، و DL یک تکنیک محاسباتی برای مقیاس‌پذیری</strong> است.</p>
<dl>
<dt>
تعریف جامع هوش مصنوعی (Artificial Intelligence - AI)
</dt>
<dd>
AI، به عنوان <strong>علم و مهندسی ساخت ماشین‌های هوشمند</strong> تعریف می‌شود. این حوزه شامل هر سیستمی است که بتواند محیط خود را درک کند و اقداماتی را انجام دهد که شانس موفقیت آن را در دستیابی به اهدافش به حداکثر برساند. توانایی‌های شناختی شبیه‌سازی شده شامل: <mark>استدلال استنتاجی، بازنمایی دانش، برنامه‌ریزی، یادگیری و ادراک (Perception)</mark> است. AI نه تنها به دنبال <strong>تقلید</strong> بلکه به دنبال <strong>ایجاد</strong> عقلانیت (Rationality) در سیستم‌های مصنوعی است.
</dd>
<dt>
مبانی ریاضی هسته‌ای AI: تئوری احتمالات و جبر خطی
</dt>
<dd>
زیربنای ML/DL مدرن بر <strong>تئوری احتمالات</strong> (برای مدیریت عدم قطعیت) و <strong>جبر خطی (Linear Algebra)</strong> استوار است. تمامی داده‌ها در DL به صورت <strong>تانسور (Tensors)</strong> نمایش داده می‌شوند. تانسورها، تعمیمی از اسکالرها (تانسور مرتبه صفر)، بردارها (تانسور مرتبه یک) و ماتریس‌ها (تانسور مرتبه دو) هستند. عملیاتی مانند ضرب نقطه‌ای (Dot Product)، کانولوشن (Convolution) و ضرب ماتریسی (Matrix Multiplication) که در معماری‌های عصبی استفاده می‌شوند، همگی عملیات تانسوری هستند.
</dd>
<dt>
یادگیری ماشین (Machine Learning - ML) و پارادایم‌ها
</dt>
<dd>
ML زیرمجموعه‌ای از AI است که بر توسعه الگوریتم‌هایی متمرکز است که به ماشین‌ها اجازه می‌دهد با تحلیل داده‌های تجربی (Empirical Data)، الگوها را شناسایی کرده و عملکرد خود را بهبود بخشند (<strong>تعریف خودکار مدل بر اساس داده</strong>). پارادایم‌های اصلی:
<ul>
<li>
<strong>Supervised Learning:</strong> آموزش بر روی داده‌های دارای برچسب برای نگاشت ورودی (<span class="math inline">\(X\)</span>) به خروجی (<span class="math inline">\(Y\)</span>) (مانند <span class="math inline">\(\text{Classification}\)</span> و <span class="math inline">\(\text{Regression}\)</span>).
</li>
<li>
<strong>Unsupervised Learning:</strong> کشف ساختار و الگوهای درونی داده‌های بدون برچسب (مانند <span class="math inline">\(\text{Clustering}\)</span> و <span class="math inline">\(\text{Dimensionality Reduction}\)</span>).
</li>
<li>
<strong>Reinforcement Learning:</strong> یادگیری از طریق تعامل با محیط (Agent-Environment interaction) برای به حداکثر رساندن پاداش تجمعی (Cumulative Reward).
</li>
</ul>
</dd>
<dt>
یادگیری عمیق (Deep Learning - DL) و شبکه عصبی عمیق
</dt>
<dd>
DL زیرمجموعه‌ای از ML است که از شبکه‌های عصبی عمیق (DNNs) استفاده می‌کند. ویژگی کلیدی DL این است که <strong>مهندسی ویژگی (Feature Engineering) به صورت خودکار</strong> در لایه‌های مدل انجام می‌شود. هر لایه، ویژگی‌های انتزاعی‌تری را از لایه قبلی استخراج می‌کند. این معماری به خوبی با داده‌های خام و پیچیده مقیاس‌پذیر است.
</dd>
</dl>
<blockquote class="keynote blockquote">
<strong>تفسیر سلسله مراتبی:</strong> AI (هدف) <span class="math inline">\(\leftarrow\)</span> ML (روش) <span class="math inline">\(\leftarrow\)</span> DL (ابزار مقیاس‌پذیر). موفقیت‌های اخیر AI (مانند LLMs) تقریباً به طور کامل مدیون پیشرفت‌های DL است.
</blockquote>
</section>
<section class="section-card">
<h3 class="anchored">
بخش دوم: تاریخچه جامع و پارادایم‌های غالب AI
</h3>
<h4 class="anchored">
۲.۱. تحلیل نقاط عطف تاریخی و چالش‌های پارادایمی
</h4>
<p>تکامل AI شامل سه دوره متمایز است که هر کدام با یک پارادایم غالب تعریف می‌شوند:</p>
<dl>
<dt>
دوره ۱: ریشه‌ها و منطق نمادین (۱۹۴۳ - ۱۹۷۴)
</dt>
<dd>
<p>
<strong>سایبرنتیک و شبکه‌های عصبی اولیه:</strong> ایده اولیه هوش مصنوعی به <strong>وارن مک‌کالوخ و والتر پیتس (۱۹۴۳)</strong> بازمی‌گردد که مدل ریاضی نورون را ارائه دادند. در دهه ۱۹۵۰، <strong>فرانک روزنبلات</strong> با ساخت <strong>پرسپترون (Perceptron)</strong>، اولین مدل یادگیری ماشینی عملی را توسعه داد.
</p>
<p>
<strong>انقلاب دارتموث (۱۹۵۶):</strong> رسماً تولد AI با مشارکت جان مک‌کارتی، ماروین مینسکی، آلن نیوول و هربرت سایمون. تمرکز بر <strong>پارادایم نمادین (Symbolic AI)</strong>، که بر این فرضیه استوار بود که هوش انسانی از دستکاری نمادها تشکیل شده است.
</p>
<p>
<strong>زبان‌های AI:</strong> توسعه <strong>LISP (۱۹۵۸)</strong> توسط مک‌کارتی (زبان اصلی AI در آمریکا) و <strong>Prolog (دهه ۱۹۷۰)</strong> (زبان اصلی در اروپا و ژاپن) برای کدنویسی دانش و منطق.
</p>
</dd>
<dt>
دوره ۲: سیستم‌های خبره و زمستان‌های AI (۱۹۷۴ - ۲۰۰۰)
</dt>
<dd>
<p>
<strong>اولین زمستان AI (۱۹۷۴):</strong> پس از گزارش لایت‌هیل (Lighthill Report) در بریتانیا، بودجه‌ها کاهش یافت. دلیل اصلی: شکست سیستم‌های نمادین در مقیاس‌پذیری و مدیریت <strong>عدم قطعیت (Uncertainty)</strong> دنیای واقعی.
</p>
<p>
<strong>سیستم‌های خبره (Expert Systems):</strong> بازگشت موقت AI در دهه ۸۰ با سیستم‌هایی مانند MYCIN. این سیستم‌ها از پایگاه داده‌های دانش گسترده و موتور استنتاج قوی (Inference Engine) برای حل مسائل در حوزه‌های تخصصی محدود استفاده می‌کردند.
</p>
<p>
<strong>دومین زمستان AI (۱۹۸۷):</strong> سیستم‌های خبره نیز در مواجهه با نگهداری گران‌قیمت، اکتساب دشوار دانش و خروج از حوزه‌های محدود، به سمت شکست رفتند.
</p>
</dd>
<dt>
دوره ۳: انقلاب آماری و یادگیری عمیق (۲۰۰۰ - امروز)
</dt>
<dd>
<p>
<strong>برتری رویکرد آماری:</strong> با پیشرفت توان محاسباتی (GPU’s) و در دسترس بودن داده‌های دیجیتال (Big Data)، پارادایم <strong>یادگیری از داده (Data-Driven)</strong> که توسط یان لکان، جفری هینتون و یوشوا بنجیو پیشگام شد، غالب گردید.
</p>
<p>
<strong>نقطه عطف DL:</strong> پیروزی AlexNet (توسط کریشفسکی، ساتسکور و هینتون) در مسابقه ImageNet در سال ۲۰۱۲، به طور قطعی برتری شبکه‌های عصبی عمیق را بر روش‌های سنتی ثابت کرد.
</p>
</dd>
</dl>
<h4 class="anchored">
۲.۲. بسط معماری‌های تخصصی در DL
</h4>
<p>مدل‌های DL فراتر از شبکه‌های عصبی چند لایه ساده هستند:</p>
<dl>
<dt>
شبکه‌های عصبی کانولوشنال (Convolutional Neural Networks - CNN)
</dt>
<dd>
متخصص در پردازش داده‌های شبکه‌ای مانند تصاویر. CNN ها از <strong>لایه کانولوشن</strong> برای استخراج ویژگی‌های محلی (مانند لبه‌ها، بافت‌ها و اشکال) استفاده می‌کنند و دارای خاصیت <strong>جابجایی‌ناپذیری (Translation Invariance)</strong> هستند که باعث کاهش تعداد پارامترها و بهبود عملکرد در بینایی ماشین می‌شود.
</dd>
<dt>
شبکه‌های عصبی بازگشتی (Recurrent Neural Networks - RNN)
</dt>
<dd>
متخصص در پردازش داده‌های ترتیبی (Sequence Data) مانند متن و صدا. RNN ها دارای یک <strong>حلقه بازخورد (Recurrent Loop)</strong> هستند که به آن‌ها اجازه می‌دهد اطلاعات را از مراحل زمانی قبل (Memory) حفظ کنند. انواع پیشرفته‌تر مانند <strong>LSTM و GRU</strong> برای حل مشکل ناپدید شدن گرادیان (Vanishing Gradient) در دنباله‌های طولانی توسعه یافتند.
</dd>
<dt>
اتوانکودرها (Autoencoders)
</dt>
<dd>
برای یادگیری بازنمایی‌های فشرده و کم‌بعد (Low-Dimensional Representations) از داده‌ها بدون نظارت استفاده می‌شوند. از دو بخش تشکیل شده‌اند: <strong>انکودر (Encoder)</strong> که داده ورودی را به یک فضای فشرده (Latent Space) نگاشت می‌کند و <strong>دیکودر (Decoder)</strong> که سعی می‌کند داده اصلی را از آن فضای فشرده بازسازی کند.
</dd>
</dl>
</section>
<section class="section-card">
<h3 class="anchored">
بخش سوم: معماری ترانسفورمر و تعمیق فنی لایه‌ها
</h3>
<h4 class="anchored">
۳.۱. معماری ترانسفورمر: فراتر از توجه (Attention)
</h4>
<p>معماری ترانسفورمر (Vaswani et al., 2017) به طور کامل RNN ها را حذف کرد و بر مبنای <strong>Parallelization</strong> و <strong>Self-Attention</strong> بنا نهاده شد. ساختار اصلی شامل دو بخش است: <strong>Encoder</strong> و <strong>Decoder</strong>.</p>
<dl>
<dt>
Positional Encoding (کدگذاری موقعیتی)
</dt>
<dd>
چون ترانسفورمر فاقد عناصر ترتیبی مانند RNN است، برای اینکه مدل ترتیب کلمات را درک کند، یک بردار موقعیتی (Position Vector) به هر ورودی اضافه می‌شود. این بردارها از توابع <strong>سینوسی و کسینوسی</strong> برای کدگذاری موقعیت‌های مختلف استفاده می‌کنند تا مدل بتواند روابط بین کلمات را بر اساس فاصله موقعیتی آن‌ها بیاموزد.
</dd>
<dt>
لایه‌های نرمال‌سازی (Layer Normalization)
</dt>
<dd>
پس از هر زیرلایه (Sublayer) - مانند لایه توجه یا لایه فیدفوروارد - یک مرحله نرمال‌سازی لایه‌ای (LayerNorm) اعمال می‌شود و سپس یک عملیات اتصال باقی‌مانده (Residual Connection) انجام می‌گیرد. LayerNorm توزیع فعال‌سازی‌ها را در هر لایه یکنواخت می‌کند، که فرآیند آموزش را بسیار پایدارتر می‌سازد.
</dd>
<dt>
لایه فیدفوروارد (Position-wise Feed-Forward Networks - FFN)
</dt>
<dd>
یک شبکه عصبی کاملاً متصل (Fully Connected) ساده است که به صورت مستقل و یکسان بر روی هر موقعیت (Position) از دنباله اعمال می‌شود. این لایه، توانایی شبکه را برای انجام <strong>تبدیل‌های غیرخطی (Non-Linear Transformations)</strong> افزایش می‌دهد.
</dd>
</dl>
<h4 class="anchored">
۳.۲. تعمیق ریاضی Scaled Dot-Product Attention
</h4>
<p>همانطور که قبلاً اشاره شد، فرمول هسته‌ای به شرح زیر است:</p>
<p><span class="math display">\[
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\]</span></p>
<dl>
<dt>
تحلیل نقش Scaling Factor (<span class="math inline">\(\sqrt{d_k}\)</span>)
</dt>
<dd>
در صورت عدم وجود این مقیاس‌بندی، با افزایش ابعاد <span class="math inline">\(d_k\)</span>، میانگین اندازه ضرب نقطه‌ای <span class="math inline">\(Q K^T\)</span> به صورت خطی افزایش می‌یابد. این افزایش باعث می‌شود که ورودی‌های Softmax بسیار بزرگ شوند و گرادیان‌های آن‌ها در مناطق صاف و اشباع (Flat Saturation Regions) قرار گیرند و به سمت صفر میل کنند (مشکل Vanishing Gradient)، که فرآیند یادگیری را مختل می‌کند. مقیاس‌بندی، واریانس ورودی‌ها به Softmax را به حدود واحد (Unit Variance) می‌رساند.
</dd>
<dt>
مفهوم Softmax در Attention
</dt>
<dd>
Softmax یک تابع تبدیل غیرخطی است که امتیازات خام شباهت را به یک توزیع احتمال معتبر تبدیل می‌کند. این خروجی، که ماتریس وزن توجه نامیده می‌شود، نشان می‌دهد که برای محاسبه خروجی در یک موقعیت خاص، چقدر باید به مقدار ورودی (Value) در موقعیت‌های دیگر “توجه” شود.
</dd>
</dl>
<blockquote class="keynote blockquote">
<strong>خلاصه فنی:</strong> ترانسفورمر با ترکیب <strong>توجه (برای وابستگی‌های جهانی)</strong>، <strong>LayerNorm/Residuals (برای پایداری آموزش)</strong>، و <strong>FFN (برای غیرخطی بودن)</strong>، یک چارچوب قدرتمند برای پردازش داده‌های دنباله‌ای ایجاد می‌کند.
</blockquote>
</section>
<section class="section-card">
<h3 class="anchored">
بخش چهارم: عامل‌های هوشمند، فلسفه و چالش‌های کلان
</h3>
<h4 class="anchored">
۴.۱. تحلیل چهار رویکرد راسل و نورویگ و فلسفه AI
</h4>
<p>درک دقیق این رویکردها، فرآیند مدل‌سازی و سنجش موفقیت در AI را روشن می‌کند. هدف AI، تحقق سیستم‌هایی است که <strong>منطقی عمل می‌کنند (Acting Rationally)</strong>.</p>
<dl>
<dt>
۱. عمل کردن مانند انسان (Acting Humanly)
</dt>
<dd>
<strong>هدف:</strong> گذراندن تست تورینگ. این رویکرد به شدت متمرکز بر عملکرد (Performance) نهایی است.
</dd>
<dt>
۲. فکر کردن مانند انسان (Thinking Humanly)
</dt>
<dd>
<strong>هدف:</strong> مدل‌سازی فرآیندهای شناختی و درونی مغز انسان. این حوزه با علوم شناختی (Cognitive Science) پیوند دارد و به دنبال ساخت مدلی است که نه تنها خروجی، بلکه نحوه استدلالش نیز شبیه انسان باشد.
</dd>
<dt>
۳. فکر کردن منطقی (Thinking Rationally)
</dt>
<dd>
<strong>هدف:</strong> سیستم‌هایی که بر اساس قوانین منطق ارسطویی و صریح کار می‌کنند. این رویکرد در AI نمادین استفاده می‌شد و محدودیت‌های جدی در مدیریت عدم قطعیت و واقعیت‌های متغیر دارد.
</dd>
<dt>
۴. عمل کردن منطقی (Acting Rationally - Rational Agent)
</dt>
<dd>
<strong>هدف:</strong> دستیابی به بهترین نتیجه مورد انتظار (Expected Optimal Outcome). این رویکرد مستقل از فرآیند فکری انسان است و به جای درست فکر کردن، بر <strong>درست عمل کردن</strong> تمرکز دارد. اکثر سیستم‌های ML/RL مدرن در این دسته قرار می‌گیرند.
</dd>
</dl>
<h4 class="anchored">
۴.۲. چالش‌های مقیاس‌پذیری و اخلاق در Generative AI
</h4>
<ul>
<li><strong>هزینه محاسباتی و مدل‌های متراکم در برابر پراکنده (Dense vs.&nbsp;Sparse Models):</strong> آموزش مدل‌های متراکم (Dense) مانند GPT-4 بسیار پرهزینه است. نوآوری‌های جدید مانند <strong>MoE (Mixture of Experts)</strong> به سمت مدل‌های پراکنده (Sparse) حرکت می‌کنند که با فعال‌سازی زیرمجموعه‌ای از پارامترها در زمان اجرا، منابع محاسباتی را به طور قابل ملاحظه‌ای کاهش می‌دهند.</li>
<li><strong>قابلیت تفسیرپذیری و اعتماد (Interpretability and Trust):</strong> مدل‌های عمیق مدرن به عنوان <strong>“جعبه سیاه” (Black Boxes)</strong> عمل می‌کنند. تلاش‌ها در حوزه <strong>XAI (Explainable AI)</strong> برای ایجاد مکانیزم‌هایی است که به انسان‌ها اجازه می‌دهد دلایل تصمیمات مدل را درک کنند، که برای کاربردهای حیاتی (مانند پزشکی) ضروری است.</li>
<li><strong>مالکیت داده و حقوق مؤلف (Data Ownership and Copyright):</strong> آموزش مدل‌های مولد بر روی حجم عظیمی از داده‌های دارای حق چاپ، مسائل حقوقی پیچیده‌ای در مورد مالکیت خروجی‌های مدل ایجاد کرده است.</li>
</ul>
</section>
<section class="section-card">
<h3 class="anchored">
بخش پنجم: مراجع آکادمیک و پیشنهادات پژوهشی عمیق
</h3>
<h4 class="anchored">
۵.۱. مراجع آکادمیک اصلی برای تعمیق دانش
</h4>
<dl>
<dt>
۱. مبانی AI و فلسفه
</dt>
<dd>
<strong>Russell, S., &amp; Norvig, P. (2020).</strong> <em>Artificial Intelligence: A Modern Approach (4th ed.).</em> Pearson Education. (مرجع استاندارد جهانی AI).
</dd>
<dt>
۲. یادگیری عمیق و ریاضیات
</dt>
<dd>
<strong>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016).</strong> <em>Deep Learning.</em> MIT Press. (مرجع فنی و ریاضی شبکه‌های عصبی).
</dd>
<dt>
۳. معماری ترانسفورمر
</dt>
<dd>
<strong>Vaswani, A., et al.&nbsp;(2017).</strong> <em>Attention Is All You Need.</em> Advances in Neural Information Processing Systems (NIPS). (مقاله بنیان‌گذار).
</dd>
</dl>
<h4 class="anchored">
۵.۲. پیشنهاد پروژه‌های ترم و تمرین‌های تفصیلی
</h4>
<ul>
<li>
<strong>پروژه ۱: پیاده‌سازی و تحلیل (Implementation &amp; Analysis):</strong> یک پیاده‌سازی ساده از یک بلوک ترانسفورمر (شامل Self-Attention، LayerNorm و FFN) با استفاده از فریمورکی مانند PyTorch یا TensorFlow انجام دهید. نقش عددی (Numerical Role) Positional Encoding را در یک دنباله کوتاه نشان دهید.
</li>
<li>
<strong>تمرین ۲: تحلیل حساسیت گرادیان و Scaling:</strong> یک تحلیل نظری و کدنویسی انجام دهید که نشان دهد در یک سناریوی ساده با <span class="math inline">\(d_k=512\)</span>، چگونه عدم استفاده از فاکتور <span class="math inline">\(\sqrt{d_k}\)</span> منجر به نرخ‌های اشباع بالاتر در تابع Softmax شده و بر پایداری به‌روزرسانی وزن‌ها (Weight Updates) تأثیر می‌گذارد.
</li>
<li>
<strong>تمرین ۳: تحقیق و گزارش XAI:</strong> گزارشی تحلیلی درباره یک روش خاص در <strong>XAI</strong> (مانند LIME یا SHAP) برای مدل‌های طبقه‌بندی تصویر تهیه کنید و نحوه تفسیرپذیر ساختن تصمیمات یک CNN در یک کاربرد پزشکی (مانند تشخیص سرطان) را توضیح دهید.
</li>
</ul>
</section>


</main></div>

 <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
 <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="footer-copyright">© 1404 - دانشگاه آزاد اسلامی واحد تهران مرکز</span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="footer-professor-name">استاد : دکتر مریم حاجی اسمعیلی</span></p>
</div>
    <div class="nav-footer-right">
<p><span class="footer-author-name">تهیه و تنظیم: ایلیا نازمهر</span></p>
</div>
  </div>
</footer>




</body></html>